mean(xcbar)
sd(xcbar)
mean(xdbar)
sd(xdbar)
# Part 3 Sampling
modboston = boston[order(boston$Department)]
# Part 3 Sampling
temp = subset(boston, boston$Department %in% head(sort(boston$Department, decreasing = TRUE)), n = 5)
temp
head(sort(boston$Department, decreasing = TRUE))
# Part 3 Sampling
temp = subset(boston, boston$Department %in% head(sort(table(boston$Department), decreasing = TRUE)), n = 5)
temp
# Part 3 Sampling
temp = subset(boston, boston$Department %in% head(sort(table(boston$Department), decreasing = TRUE), n = 5))
temp
head(sort(table(boston$Department), decreasing = TRUE), n = 5)
rer = head(sort(table(boston$Department), decreasing = TRUE), n = 5)
rer
# Part 3 Sampling
temp = as.data.frame(head(sort(table(boston$Department), decreasing = TRUE), n = 5))
temp
# Part 3 Sampling
temp = as.data.frame(head(sort(table(boston$Department), decreasing = TRUE), n = 5))
modboston = boston[boston$Department %in% temp$Var1]
# Part 3 Sampling
temp = as.data.frame(head(sort(table(boston$Department), decreasing = TRUE), n = 5))
modboston = boston[subset(boston$Department %in% temp$Var1)]
boston <- read.csv("https://people.bu.edu/kalathur/datasets/bostonCityEarnings.csv", colClasses = c("character", "character", "character", "integer", "character"))
# Part 1 Central Limit Theorem
# a) Draw Histogram and calculate mean & SD
hist(boston$Earnings, breaks = seq(from = 40000, to = 400000, by = 20000))
mean(boston$Earnings)
sd(boston$Earnings)
# b) Draw 5000 Samples of size 10, show histogram and calculate mean & SD
samples = 5000
xbar = numeric(samples)
set.seed(4148)
for(x in 1: samples) {
xbar[x] = mean(rnorm(10, mean = mean(boston$Earnings), sd = sd(boston$Earnings)))
}
mean(xbar)
sd(xbar)
hist(xbar, probability = TRUE)
# c) Draw 5000 Samples of size 40, show histogram and calculate mean & SD
ybar = numeric(samples)
set.seed(4148)
for(y in 1: samples) {
ybar[y] = mean(rnorm(40, mean = mean(boston$Earnings), sd = sd(boston$Earnings)))
}
mean(ybar)
sd(ybar)
hist(ybar, probability = TRUE)
# Part 2 Central Limit Theorem – Negative Binomial Distribution
# a) Generate 5000 random values from this distribution
x2bar = numeric(5000)
set.seed(4148)
for(z in 1: 5000) {
x2bar[z] = mean(rnbinom(5000, size = 3, prob = 0.5))
}
barplot(prop.table(table(x2bar)), xlab = "z", ylab = "Proportion")
mean(x2bar)
sd(x2bar)
# b) With samples sizes of 10, 20, 30, and 40, draw 1000 samples from the data generated in a).
xabar = numeric(1000)
xbbar = numeric(1000)
xcbar = numeric(1000)
xdbar = numeric(1000)
# Sample size 10
for(a in 1 : 1000){
xabar[a] = mean(sample(10, size = 3, replace = FALSE))
}
# Sample size 20
for(b in 1 : 1000){
xbbar[b] = mean(sample(20, size = 3, replace = FALSE))
}
# Sample size 30
for(c in 1 : 1000){
xcbar[c] = mean(sample(30, size = 3, replace = FALSE))
}
# Sample size 40
for(d in 1 : 1000){
xdbar[d] = mean(sample(40, size = 3, replace = FALSE))
}
par(mfrow=c(2,2))
hist(xabar)
hist(xbbar)
hist(xcbar)
hist(xdbar)
mean(xabar)
sd(xabar)
mean(xbbar)
sd(xbbar)
mean(xcbar)
sd(xcbar)
mean(xdbar)
sd(xdbar)
# Part 3 Sampling
temp = as.data.frame(head(sort(table(boston$Department), decreasing = TRUE), n = 5))
# a
# b
# c
# d
# e
View(temp)
source("~/CS544_HW5_TAI_4148.R")
modboston = subset(boston, boston$Department %in% temp)
View(modboston)
modboston = subset(boston, temp %in% boston$Department)
View(modboston)
View(modboston)
modboston = boston[which(boston$Department %in% tempdir())]
View(modboston)
source("~/CS544_HW5_TAI_4148.R")
boston <- read.csv("https://people.bu.edu/kalathur/datasets/bostonCityEarnings.csv", colClasses = c("character", "character", "character", "integer", "character"))
# Part 1 Central Limit Theorem
# a) Draw Histogram and calculate mean & SD
hist(boston$Earnings, breaks = seq(from = 40000, to = 400000, by = 20000))
mean(boston$Earnings)
sd(boston$Earnings)
# b) Draw 5000 Samples of size 10, show histogram and calculate mean & SD
samples = 5000
xbar = numeric(samples)
set.seed(4148)
for(x in 1: samples) {
xbar[x] = mean(rnorm(10, mean = mean(boston$Earnings), sd = sd(boston$Earnings)))
}
mean(xbar)
sd(xbar)
hist(xbar, probability = TRUE)
# c) Draw 5000 Samples of size 40, show histogram and calculate mean & SD
ybar = numeric(samples)
set.seed(4148)
for(y in 1: samples) {
ybar[y] = mean(rnorm(40, mean = mean(boston$Earnings), sd = sd(boston$Earnings)))
}
mean(ybar)
sd(ybar)
hist(ybar, probability = TRUE)
# Part 2 Central Limit Theorem – Negative Binomial Distribution
# a) Generate 5000 random values from this distribution
x2bar = numeric(5000)
set.seed(4148)
for(z in 1: 5000) {
x2bar[z] = mean(rnbinom(5000, size = 3, prob = 0.5))
}
barplot(prop.table(table(x2bar)), xlab = "z", ylab = "Proportion")
mean(x2bar)
sd(x2bar)
# b) With samples sizes of 10, 20, 30, and 40, draw 1000 samples from the data generated in a).
xabar = numeric(1000)
xbbar = numeric(1000)
xcbar = numeric(1000)
xdbar = numeric(1000)
# Sample size 10
for(a in 1 : 1000){
xabar[a] = mean(sample(10, size = 3, replace = FALSE))
}
# Sample size 20
for(b in 1 : 1000){
xbbar[b] = mean(sample(20, size = 3, replace = FALSE))
}
# Sample size 30
for(c in 1 : 1000){
xcbar[c] = mean(sample(30, size = 3, replace = FALSE))
}
# Sample size 40
for(d in 1 : 1000){
xdbar[d] = mean(sample(40, size = 3, replace = FALSE))
}
par(mfrow=c(2,2))
hist(xabar)
hist(xbbar)
hist(xcbar)
hist(xdbar)
mean(xabar)
sd(xabar)
mean(xbbar)
sd(xbbar)
mean(xcbar)
sd(xcbar)
mean(xdbar)
sd(xdbar)
# Part 3 Sampling
temp = as.data.frame(head(sort(table(boston$Department), decreasing = TRUE), n = 5))
modboston = boston[which(boston$Department %in% temp$Var1]
boston <- read.csv("https://people.bu.edu/kalathur/datasets/bostonCityEarnings.csv", colClasses = c("character", "character", "character", "integer", "character"))
# Part 1 Central Limit Theorem
# a) Draw Histogram and calculate mean & SD
hist(boston$Earnings, breaks = seq(from = 40000, to = 400000, by = 20000))
mean(boston$Earnings)
sd(boston$Earnings)
# b) Draw 5000 Samples of size 10, show histogram and calculate mean & SD
samples = 5000
xbar = numeric(samples)
set.seed(4148)
for(x in 1: samples) {
xbar[x] = mean(rnorm(10, mean = mean(boston$Earnings), sd = sd(boston$Earnings)))
}
mean(xbar)
sd(xbar)
hist(xbar, probability = TRUE)
# c) Draw 5000 Samples of size 40, show histogram and calculate mean & SD
ybar = numeric(samples)
set.seed(4148)
for(y in 1: samples) {
ybar[y] = mean(rnorm(40, mean = mean(boston$Earnings), sd = sd(boston$Earnings)))
}
mean(ybar)
sd(ybar)
hist(ybar, probability = TRUE)
# Part 2 Central Limit Theorem – Negative Binomial Distribution
# a) Generate 5000 random values from this distribution
x2bar = numeric(5000)
set.seed(4148)
for(z in 1: 5000) {
x2bar[z] = mean(rnbinom(5000, size = 3, prob = 0.5))
}
barplot(prop.table(table(x2bar)), xlab = "z", ylab = "Proportion")
mean(x2bar)
sd(x2bar)
# b) With samples sizes of 10, 20, 30, and 40, draw 1000 samples from the data generated in a).
xabar = numeric(1000)
xbbar = numeric(1000)
xcbar = numeric(1000)
xdbar = numeric(1000)
# Sample size 10
for(a in 1 : 1000){
xabar[a] = mean(sample(10, size = 3, replace = FALSE))
}
# Sample size 20
for(b in 1 : 1000){
xbbar[b] = mean(sample(20, size = 3, replace = FALSE))
}
# Sample size 30
for(c in 1 : 1000){
xcbar[c] = mean(sample(30, size = 3, replace = FALSE))
}
# Sample size 40
for(d in 1 : 1000){
xdbar[d] = mean(sample(40, size = 3, replace = FALSE))
}
par(mfrow=c(2,2))
hist(xabar)
hist(xbbar)
hist(xcbar)
hist(xdbar)
mean(xabar)
sd(xabar)
mean(xbbar)
sd(xbbar)
mean(xcbar)
sd(xcbar)
mean(xdbar)
sd(xdbar)
# Part 3 Sampling
temp = as.data.frame(head(sort(table(boston$Department), decreasing = TRUE), n = 5))
modboston = boston[which(boston$Department %in% temp$Var1)]
View(temp)
View(temp)
modboston = boston[which(names(boston$Department) %in% temp$Var1)]
modboston = boston[which(names(boston$Department) %in% names(temp$Var1))]
View(modboston)
modboston = boston[which(boston$Department %in% temp$Var1)]
modboston = boston[which(boston$Department %in% temp$Var1),]
View(modboston)
temp
# a
srswor(50, set.seed(4148))
library(sampling)
library('sampling')
install.packages('sampling')
library('sampling')
temp = as.data.frame(head(sort(table(boston$Department), decreasing = TRUE), n = 5))
modboston = boston[which(boston$Department %in% temp$Var1),]
# a
srswor(50, set.seed(4148))
xabar
source("~/CS544_HW5_TAI_4148.R")
install.packages('sampling')
boston <- read.csv("https://people.bu.edu/kalathur/datasets/bostonCityEarnings.csv", colClasses = c("character", "character", "character", "integer", "character"))
# Part 1 Central Limit Theorem
# a) Draw Histogram and calculate mean & SD
hist(boston$Earnings, breaks = seq(from = 40000, to = 400000, by = 20000))
mean(boston$Earnings)
sd(boston$Earnings)
# b) Draw 5000 Samples of size 10, show histogram and calculate mean & SD
samples = 5000
xbar = numeric(samples)
set.seed(4148)
for(x in 1: samples) {
xbar[x] = mean(rnorm(10, mean = mean(boston$Earnings), sd = sd(boston$Earnings)))
}
mean(xbar)
sd(xbar)
hist(xbar, probability = TRUE)
# c) Draw 5000 Samples of size 40, show histogram and calculate mean & SD
ybar = numeric(samples)
set.seed(4148)
for(y in 1: samples) {
ybar[y] = mean(rnorm(40, mean = mean(boston$Earnings), sd = sd(boston$Earnings)))
}
mean(ybar)
sd(ybar)
hist(ybar, probability = TRUE)
# Part 2 Central Limit Theorem – Negative Binomial Distribution
# a) Generate 5000 random values from this distribution
x2bar = numeric(5000)
set.seed(4148)
for(z in 1: 5000) {
x2bar[z] = mean(rnbinom(5000, size = 3, prob = 0.5))
}
barplot(prop.table(table(x2bar)), xlab = "z", ylab = "Proportion")
mean(x2bar)
sd(x2bar)
# b) With samples sizes of 10, 20, 30, and 40, draw 1000 samples from the data generated in a).
xabar = numeric(1000)
xbbar = numeric(1000)
xcbar = numeric(1000)
xdbar = numeric(1000)
# Sample size 10
for(a in 1 : 1000){
xabar[a] = mean(sample(10, size = 3, replace = FALSE))
}
# Sample size 20
for(b in 1 : 1000){
xbbar[b] = mean(sample(20, size = 3, replace = FALSE))
}
# Sample size 30
for(c in 1 : 1000){
xcbar[c] = mean(sample(30, size = 3, replace = FALSE))
}
# Sample size 40
for(d in 1 : 1000){
xdbar[d] = mean(sample(40, size = 3, replace = FALSE))
}
par(mfrow=c(2,2))
hist(xabar)
hist(xbbar)
hist(xcbar)
hist(xdbar)
mean(xabar)
sd(xabar)
mean(xbbar)
sd(xbbar)
mean(xcbar)
sd(xcbar)
mean(xdbar)
sd(xdbar)
# Part 3 Sampling
library('sampling')
temp = as.data.frame(head(sort(table(boston$Department), decreasing = TRUE), n = 5))
modboston = boston[which(boston$Department %in% temp$Var1),]
# a
set.seed(4148)
table(modboston$Department)
s1 = srswor(50, nrow(modboston))
s1[s1 != 0]
rows = (1:nrow(modboston))[s1 != 0]
rows = rep(rows, s1[s1 != 0])
rows
samplea = modboston[rows,]
table(samplea$Department)
# b
k = ceiling(nrow(modboston)/ 50)
sample(k, 1)
s2 = seq(sample(k, 1), by = k, length = 50)
sampleb <- modboston[s2,]
table(sampleb$Department)
# c
pik = inclusionprobabilities(modboston$Earnings, 50)
s3 = UPsystematic(pik)
samplec <- modboston[s3 != 0,]
table(samplec$Earnings)
# d
s4 <- strata(modboston, stratanames = c("Department"), size = rep(50, nrow(modboston)), method = "srswor", description = TRUE)
# e
mean(modboston$Earnings)
mean(samplea$Earnings)
mean(sampleb$Earnings)
mean(samplec$Earnings)
# Removes the scientific notation on the labels and gives whole numbers
options(scipen = 999)
s4 <- strata(modboston, stratanames = c("Department"), size = rep(50, nrow(modboston)), method = "srswor", description = TRUE)
sampled <- modboston[s4 != 0,]
# e
mean(modboston$Earnings)
mean(samplea$Earnings)
mean(sampleb$Earnings)
mean(samplec$Earnings)
# d
s4 <- strata(modboston, stratanames = c("Department"), size = rep(50, nrow(modboston)), method = "srswor", description = TRUE)
sampled <- modboston[s4 != 0,]
# e
mean(modboston$Earnings)
mean(samplea$Earnings)
mean(sampleb$Earnings)
mean(samplec$Earnings)
mean(sampled$Earnings)
sampled
# d
s4 <- strata(modboston, stratanames = c("Department"), size = rep(50, nrow(modboston)), method = "srswor", description = TRUE)
sampled <- modboston[s4 != 0,]
# e
mean(modboston$Earnings)
mean(samplea$Earnings)
mean(sampleb$Earnings)
mean(samplec$Earnings)
mean(sampled$Earnings)
source("~/CS544_HW5_TAI_4148.R")
# Removes the scientific notation on the labels and gives whole numbers
options(scipen = 999)
install.packages('sampling')
boston <- read.csv("https://people.bu.edu/kalathur/datasets/bostonCityEarnings.csv", colClasses = c("character", "character", "character", "integer", "character"))
# Part 1 Central Limit Theorem
# a) Draw Histogram and calculate mean & SD
hist(boston$Earnings, breaks = seq(from = 40000, to = 400000, by = 20000), main = "Histogram of Earnings", xlab = "Earnings")
mean(boston$Earnings)
sd(boston$Earnings)
# b) Draw 5000 Samples of size 10, show histogram and calculate mean & SD
samples = 5000
xbar = numeric(samples)
set.seed(4148)
for(x in 1: samples) {
xbar[x] = mean(rnorm(10, mean = mean(boston$Earnings), sd = sd(boston$Earnings)))
}
mean(xbar)
sd(xbar)
hist(xbar, probability = TRUE, main = "Histogram for data size 10")
# c) Draw 5000 Samples of size 40, show histogram and calculate mean & SD
ybar = numeric(samples)
set.seed(4148)
for(y in 1: samples) {
ybar[y] = mean(rnorm(40, mean = mean(boston$Earnings), sd = sd(boston$Earnings)))
}
setwd("~")
getwd()
qf(0.95, df1 = 4, df2 = 14)
setwd("C:/Users/danie/Desktop/CS 555 Found of ML/Term Project")
# Removes the scientific notation on the labels and gives whole numbers
options(scipen = 999)
# Removes the scientific notation on the labels and gives whole numbers
options(scipen = 999)
# Read Original Data Set
raw = read.csv("C:/Users/danie/Desktop/CS 555 Found of ML/Term Project/adm_data.csv")
# Clean Data
data = raw[-c(1)]
# Use cor() function to determine the correlation coefficient between each factor individually against the Chances of admittance
cor(data)
pairs(data)
#
# Calculate Least Squares Regression Equation
# Build a Multiple Linear Regression(MLR) model then run summary() on the model
model1 = lm(data$Chance.of.Admit ~ data$GRE.Score + data$TOEFL.Score + data$University.Rating + data$SOP + data$LOR + data$CGPA + data$Research)
summary(model1)
#
# Calculate R^2
totalss = sum((data$Chance.of.Admit - mean(data$Chance.of.Admit))^2)
regss = sum((fitted(model1) - mean(data$Chance.of.Admit))^2)
resiss = sum((data$Chance.of.Admit - fitted(model1))^2)
R2 = regss / totalss
#
# Run Global F-Test, use qf() to determine decision rule at alpha = 0.01
# We do a minus 1 in the ncol(data) to remove the observed/dependent variable $Admission Chance
qf(0.99, df1 = ncol(data) - 1, df2 = nrow(data) - (ncol(data) - 1) - 1)
#
# Run inference t-test for each parameter using qt() to determine decision rule at alpha = 0.05
qt(0.975, df = nrow(data) - 1)
#
# Calculate the 95% confidence intervals for variables of which the null hypothesis we rejected
model2 = lm(data$Chance.of.Admit ~ data$GRE.Score + data$TOEFL.Score + data$University.Rating + data$SOP + data$LOR + data$CGPA + data$Research)
confint(model2, level = 0.95)
#
# Check if MLR satisfies the assumptions
plot(model2)
# Removes the scientific notation on the labels and gives whole numbers
options(scipen = 999)
# Read Original Data Set
raw = read.csv("C:/Users/danie/Desktop/CS 555 Found of ML/Term Project/adm_data.csv")
# Clean Data
data = raw[-c(1)]
# Use cor() function to determine the correlation coefficient between each factor individually against the Chances of admittance
cor(data)
pairs(data)
#
# Calculate Least Squares Regression Equation
# Build a Multiple Linear Regression(MLR) model then run summary() on the model
model1 = lm(data$Chance.of.Admit ~ data$GRE.Score + data$TOEFL.Score + data$University.Rating + data$SOP + data$LOR + data$CGPA + data$Research)
summary(model1)
#
# Calculate R^2
totalss = sum((data$Chance.of.Admit - mean(data$Chance.of.Admit))^2)
regss = sum((fitted(model1) - mean(data$Chance.of.Admit))^2)
resiss = sum((data$Chance.of.Admit - fitted(model1))^2)
R2 = regss / totalss
#
# Run Global F-Test, use qf() to determine decision rule at alpha = 0.01
# We do a minus 1 in the ncol(data) to remove the observed/dependent variable $Admission Chance
qf(0.99, df1 = ncol(data) - 1, df2 = nrow(data) - (ncol(data) - 1) - 1)
#
# Run inference t-test for each parameter using qt() to determine decision rule at alpha = 0.05
qt(0.975, df = nrow(data) - 1)
#
# Calculate the 95% confidence intervals for variables of which the null hypothesis we rejected
model2 = lm(data$Chance.of.Admit ~ data$GRE.Score + data$TOEFL.Score + data$University.Rating + data$SOP + data$LOR + data$CGPA + data$Research)
confint(model2, level = 0.95)
#
# Hist() model residual to confirm Normal Q-Q plot
hist(residuals(model2), main = "Model Residuals to confirm Normality", xlab = "Residuals")
#
# Check if MLR satisfies the assumptions
plot(model2)
